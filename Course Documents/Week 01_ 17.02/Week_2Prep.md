# PHKI â€“ Week 2 Preparation: Resource Summaries

> **Purpose:** This document summarises the 5 text-based resources assigned on Slide 26 (Week 1) so you can participate in the Week 2 discussion. The podcast (*Art and AI with RaphaÃ«l MilliÃ¨re*) is excluded since it cannot be summarised in text form.
>
> **What you need for class:** Pick **one** resource, read this summary (and ideally skim the original), and be ready to discuss:
> 1. What is the main argument?
> 2. What future does it imagine?
> 3. Do you agree?
>
> **Remember (Slide 26 tip):** *"Take note of each publisher/company. Is it possible that they are trying to push a certain narrative? Who is funding them?"*

---

## 1. ðŸ—žï¸ "AI won an art contest, and artists are furious" (CNN, 2022)

**Source:** [CNN Business](https://edition.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy) | **Author:** Rachel Metz | **Format:** News Article (~10 min read)

### What Happened

- **Jason M. Allen**, a game designer from Colorado, won **first place** in the "digital arts/digitally-manipulated photography" category at the **Colorado State Fair Fine Arts Competition** (August 2022).
- His winning image, *"ThÃ©Ã¢tre D'opÃ©ra Spatial"*, was created using **Midjourney** â€” an AI image generator that produces images from text prompts.
- Allen disclosed his use of Midjourney when entering the contest. The category definition includes works that use "digital technology as part of the creative or presentation process."

### The Controversy

- The win **went viral on Twitter**, with many artists furious that an AI-generated work won a traditional art competition.
- Critics argued: *"This sucks for the exact same reason we don't let robots participate in the Olympics"* and called it *"the literal definition of 'pressed a few buttons to make a digital art piece'."*
- Allen countered that his process took **over 80 hours**: he created **900 iterations** with tweaked prompts, refined images in Photoshop, upscaled with Gigapixel AI, and had them printed on canvas.

### Key Arguments

| Position | Argument |
|---|---|
| **Pro-Allen** | AI is a powerful tool â€” "we need to recognize that it's a powerful tool and use it for good." The creative vision, curation, and refinement constitute genuine artistry. |
| **Anti-AI art** | AI removes the skill and labour that traditionally define artistry. Allowing AI in competitions devalues human artists. |
| **Judge's view** | Cal Duran (judge) didn't realise it was AI but stood by his decision: *"I think there's a lot involved in this piece"* â€” AI may give opportunities to people who aren't conventional artists. |

### The 3 Discussion Questions

1. **Main argument:** AI art tools are legitimate creative instruments; the artistic process involves prompt engineering, curation, and post-processing, not just "pressing a button."
2. **Future imagined:** A world where AI-human collaboration is a recognised form of artistic practice, accepted (and debated) in traditional art institutions.
3. **Do you agree?** Consider: Is 80 hours of prompt iteration comparable to 80 hours of painting? Does the institutional context (a state fair) matter?

### ðŸ” Source Evaluation

- **Publisher:** CNN Business â€” major global news outlet, generally centrist
- **Possible bias:** The article is fairly balanced, presenting both sides. CNN has no obvious financial stake in AI art.
- **Note:** The article profiles Allen sympathetically while acknowledging artist outrage â€” consider if the "innovative disruptor" framing subtly normalises AI art.

---

## 2. ðŸŽ¥ "The New Ethics of AI" (Markus Gabriel, DLD Munich 2024)

**Source:** [DLD News](https://dldnews.com/videos/the-new-ethics-of-ai/) | **Speaker:** Markus Gabriel (University of Bonn) | **Format:** Video talk (~15 min)

### Who is Markus Gabriel?

- German philosopher, chair of epistemology at the **University of Bonn**
- Leading thinker on ethics, ontology, and epistemology; work translated into 15 languages
- Bestselling author â€” known for making philosophy accessible

### Main Arguments

1. **AI systems are not truly intelligent like humans**, but their deployment disrupts society in ways that require **normative (ethical) guidance**.
2. **"Ethics of AI deals with moral facts pertaining to the production and use of AI systems"** â€” ethics is not optional window-dressing but a necessary framework for responsible development.
3. AI can be designed to have a **positive impact** if its goal is to further **moral progress** â€” but this contrasts sharply with military applications (drones, autonomous weapons).
4. **"The most effective way of social implementation is through the economy"** â€” Gabriel argues that combining techno-scientific, economic, and moral progress through AI can lead to "a new scale of human progress."

### Key Thesis

> AI systems can advance humanity **if and only if** they are guided by ethical frameworks that prioritise moral progress over pure efficiency or profit.

### The 3 Discussion Questions

1. **Main argument:** AI needs a new ethical framework â€” not just regulation, but a fundamental moral compass guiding its production and use.
2. **Future imagined:** Optimistic â€” AI as a driver of human moral, economic, and scientific progress, provided ethics are embedded from the start.
3. **Do you agree?** Consider: Is Gabriel too optimistic? Can "moral progress" be defined objectively? Who decides what counts as ethical AI?

### ðŸ” Source Evaluation

- **Publisher:** DLD (Digital Life Design) â€” conference series affiliated with **Hubert Burda Media** (German media company)
- **Possible bias:** DLD is a tech-industry conference. Speakers often lean pro-innovation. Gabriel's optimism about AI may align with DLD's generally tech-positive framing.
- **Funding:** RenÃ© Scheu (moderator) is from the Institute for Swiss Economic Policy at the University of Lucerne â€” academic/policy perspective.

---

## 3. ðŸ“„ "An Economic Solution to Copyright Challenges of Generative AI" (arXiv, 2024)

**Source:** [arXiv](https://arxiv.org/abs/2404.13964) | **Format:** Academic paper (technical, ~30 min skim)

### The Problem

- Generative AI systems are trained on vast datasets of copyrighted works (images, text, music).
- There is growing concern that these systems **infringe on copyright** â€” artists receive no compensation when their work is used to train models that generate competing outputs.

### Proposed Solution

- The authors propose a **compensation framework** that pays copyright owners **proportionally to their contribution** to AI-generated content.
- The contribution metric uses techniques from **cooperative game theory** (specifically Shapley values from economics) to quantify how much each training data source influenced a given AI output.
- This creates a **platform model**: AI developers get access to high-quality training data â†’ model performance improves. Copyright owners receive fair payment â†’ they continue providing data.

### Key Thesis

> The copyright problem of generative AI can be solved economically through a **proportional revenue-sharing framework** rather than through outright bans or unregulated use.

### The 3 Discussion Questions

1. **Main argument:** Copyright disputes can be resolved by fairly compensating artists based on measurable contributions to AI outputs, using game theory.
2. **Future imagined:** A marketplace where AI companies and artists coexist â€” artists are paid for their contributions, AI companies benefit from willing data providers.
3. **Do you agree?** Consider: Is proportional compensation technically feasible at scale? Does it reduce art to a data commodity? Would major AI companies voluntarily adopt this?

### ðŸ” Source Evaluation

- **Publisher:** arXiv â€” open-access, **not peer-reviewed** (preprints). The paper's quality must be assessed on its own merits.
- **Possible bias:** The authors propose a technical solution â€” academics often favour frameworks that can be modelled mathematically. Economic framing may overlook ethical or emotional dimensions of creative work.

---

## 4. ðŸ›ï¸ "AI and the visual arts: The case for copyright protection" (Brookings, 2025)

**Source:** [Brookings Institution](https://www.brookings.edu/articles/ai-and-the-visual-arts-the-case-for-copyright-protection/) | **Authors:** Judy Wang & Nicol Turner Lee | **Format:** Policy article (~12 min read)

### Context

- The global GenAI art market is expected to grow by **42% through 2029**, reaching **$2.5 billion**.
- Tools like DALL-E, Midjourney, and Adobe's AI features have **flooded the art market** with AI-generated or partially AI-generated works.
- Recent viral example: ChatGPT's Studio Ghibli-style image feature reached **15 million weekly active users**.

### Key Legal Arguments

| Issue | Current Situation |
|---|---|
| **U.S. Copyright Office position** | Only "original works of authorship" by a **human agent** can be copyrighted. AI-generated outputs from prompt engineering **do not qualify**. |
| **AI-generated elements** | Even within a human-authored work, AI-generated portions are excluded from copyright protection. |
| **Fair Use for training data** | Unresolved. GenAI companies argue training on copyrighted data is Fair Use. The Copyright Office hasn't clarified â€” artists must sue individually. |
| **Enforcement problem** | The Copyright Office **cannot distinguish** AI-generated from human-made elements without voluntary disclosure â€” creating a perverse incentive not to disclose. |

### Real Case: *Zarya of the Dawn*

- In 2023, the Copyright Office **rescinded copyright** for a comic book that used Midjourney-generated images.
- Only the "selection, coordination, and arrangement" by the human author was protected â€” not the AI-generated images themselves.

### Proposed Solutions

1. **New copyright category** for human-AI collaborative works â€” recognising human creative direction while accommodating AI assistance.
2. **Stronger disclosure requirements** and better detection methods for AI-generated content.
3. **Legislative action** needed â€” the current legal gap allows AI companies to train on copyrighted data without compensation.

### Global Context

| Country | Approach |
|---|---|
| **USA** | Human authorship required; AI outputs not copyrightable |
| **UK** | Copyright for computer-generated works goes to whoever arranged the creation |
| **China** | Copyright recognised if prompts are sufficiently detailed |

### The 3 Discussion Questions

1. **Main argument:** Current copyright law is insufficient to protect human artists from AI-driven devaluation. Legislative safeguards are urgently needed.
2. **Future imagined:** Without action â€” systemic devaluation of human authorship and economic precarity for artists. With action â€” balanced frameworks protecting creativity while allowing innovation.
3. **Do you agree?** Consider: Should a new copyright category for AI-human collaboration exist? Does the UK or Chinese approach make more sense than the US position?

### ðŸ” Source Evaluation

- **Publisher:** Brookings Institution â€” influential **centre-left think tank** in Washington, D.C., known for evidence-based policy analysis.
- **Possible bias:** Brookings has a **general, unrestricted donation from Google** (disclosed at the end of the article). The authors state findings are not influenced by donations â€” but this is worth noting given Google's interest in AI art tools.
- **Framing:** The article favours stronger protections for artists â€” consider whether this reflects the authors' genuine analysis or an institutional stance.

---

## 5. ðŸ”¬ "Eyes can tell: Assessment of implicit attitudes toward AI art" (Zhou et al., Frontiers in Psychology, 2023)

**Source:** [Frontiers in Psychology / PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC10663653/) | **Authors:** Zhou, Yang, Wang, Zhang & Luo | **Format:** Peer-reviewed research paper (~30 min read)

### Research Question

Do people have an **implicit (unconscious) bias** against AI-generated art, even when they can't tell whether art is human-made or AI-generated?

### Method

- Participants viewed paintings (landscape paintings â€” both human-made and AI-generated via Disco Diffusion).
- **Eye-tracking** measured **implicit** responses (where and how long people look).
- **Subjective ratings** measured **explicit** responses (beauty, liking, arousal, familiarity).
- Participants also tried to **categorise** each painting as human-made or AI-made.

### Key Findings

| Measure | Result |
|---|---|
| **Identification accuracy** | Poor â€” participants could not reliably tell human from AI art |
| **Eye-tracking (implicit)** | Paintings **categorised as human-made** received **331ms longer fixation duration** â€” people unconsciously looked longer at art they believed was human |
| **Subjective ratings (explicit)** | **No significant difference** â€” human and AI art were rated similarly on beauty, liking, and emotional response |
| **Categorisation bias** | Representational/realistic paintings were more likely to be assumed human-made; abstract works more often assumed to be AI |

### Key Thesis

> People hold an **implicit negative bias** against AI art that manifests in unconscious visual attention, even when their conscious aesthetic judgments show no difference. Artistic creativity is still considered a "human prerogative" at a deep psychological level.

### What This Means

- The bias is **real but hidden** â€” people don't consciously rate AI art lower, but their eyes "know."
- This has implications for how AI art is exhibited, marketed, and received â€” **labelling art as AI-generated may trigger unconscious devaluation**.
- It connects directly to the Gallery Walk question from Week 1: *"Would you care if/that they were AI-created?"* â€” the answer may be "yes, even if you don't realise it."

### The 3 Discussion Questions

1. **Main argument:** An unconscious, implicit bias against AI art exists â€” people instinctively privilege human-made art even when they can't consciously distinguish it.
2. **Future imagined:** As AI art becomes visually indistinguishable from human art, the battle will shift from quality to **attribution** â€” knowing who made it will matter more than how it looks.
3. **Do you agree?** Consider: If the bias is unconscious, should galleries be required to label AI art? Does this bias reflect something meaningful about human creativity, or is it just prejudice?

### ðŸ” Source Evaluation

- **Publisher:** *Frontiers in Psychology* â€” **peer-reviewed** open-access journal. Generally reputable, though Frontiers journals have been criticised for variable quality control.
- **Possible bias:** Academic research â€” the authors have no obvious commercial interest. However, the study only used **landscape paintings** â€” results may not generalise to other art forms (music, poetry, abstract art).
- **Sample:** Small sample size, likely university students â€” cultural and demographic bias possible.

---

## Quick Comparison: All 5 Resources

| Resource | Perspective | Main Lens | Key Takeaway |
|---|---|---|---|
| **CNN** (Allen story) | Journalistic | Institutional | AI art can win traditional competitions â€” the question is whether it should |
| **Gabriel** (DLD video) | Philosophical | Philosophical | AI needs an ethical framework grounded in moral progress |
| **arXiv paper** | Technical/Economic | Economic | Compensate artists proportionally using game theory |
| **Brookings** | Legal/Policy | Institutional + Economic | Copyright law must adapt â€” human artists need legislative protection |
| **Zhou et al.** | Empirical/Scientific | Philosophical | Implicit bias against AI art exists at an unconscious level |

---

## ðŸ’¡ Discussion Starter: Connecting All Resources

All five resources orbit the same core tension: **AI can produce art that is visually indistinguishable from human art â€” but the human response to AI art is shaped by attribution, economics, and deep-seated psychological biases.**

Possible synthesis for class discussion:

> *"The problem isn't whether AI art is good enough â€” Zhou et al. show people can't tell the difference. The problem is who gets credit (CNN/Allen), who gets paid (arXiv/Brookings), and whether we can design AI systems that serve moral rather than purely economic ends (Gabriel). These are not separate issues â€” they are all facets of the same question: What do we value in art, and how should AI change that?"*

---

*Compiled from original sources for PHKI Week 2 preparation. The podcast (Overthink Ep. 80) is excluded as it cannot be summarised from text. All source evaluations follow the Slide 26 tip: "Who is funding them?"*
